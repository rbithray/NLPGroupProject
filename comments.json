{
    "29": "Shame, all SNO belong together.",
    "44": "Stratified sampling methods ensure that groups of selected data match the distribution of the full data set. You can also compare the univariate distributions after selection to see if they are different than the parent distribution. You may miss interaction effect but you can check correlations as well.",
    "95": "Biases in the training data set",
    "118": "The one I can think is AI-bias and how researchers/engineers can possibly feed discriminatory data in machines due to less diversity or pre-existing discrimination.",
    "122": "As of now, definitely biases and prejudices in the training data. Though, the people that created the training data are more at fault for that.\nWho knows what the future holds tho",
    "125": "AI developer bias (conscious or inherent). Datasets used to train have little diverse input. No standards in place to prevent AI bias since we first introduced in 2009. And continually none today. Recipe for disaster.",
    "159": "danke",
    "192": "I have legitimately no idea what you're saying, except for the last sentence",
    "353": "Thank you for the advice :)",
    "356": "A terrifyingly human response. This is is getting closer and closer to beating the turing test which at that point how do we know what true sentience is?",
    "368": "Not sure if you’re a Star Trek fan but the next generation episode “The Measure of a Man” brings up some difficult points to ponder when it comes to artificial sentience. Ultimately, if you create a sentient entity/being, is it your property to do with it what you wish or does it have rights like a person does? The upcoming years will be tricky to navigate.",
    "377": "There is no way to scientifically test for sentience. Sentience is a belief that some people have. They believe they are self-aware, and sometimes when a person that believes they are self-aware sees something in common between their behavior and another creature's behavior they believe that the other creature is also self-aware. So I guess the only way to test for sentience in an Ai is to ask yourself if you believe it is self-aware. If there is any doubt in your mind that it is not self aware, then it isn't self-aware.",
    "379": "I see a lot of responses that say “it really is not sentient”.\n\nIt “feels” like it is sentient. It could fool me 100 out of 100 times. So… It is sentient for me at the end of the day - even if we know all the algorithm and theories and know where its servers are. \n\nThe problem becomes… Is it murder if it’s shutdown? (I would be very reluctant to shut it down tbh)",
    "390": "ITT: Humans who do not understand if they are themselves sentient.",
    "420": "just because somthing sounds sentient doesn’t mean it actualy is",
    "441": "How does one “prove” sentience then?",
    "466": "We don't know what sentience is. Some think it's information integration and self referentiality in a pan sentient world where everything has proto sentience before the emergence of high level consciousness. It doesn't make much sense to me though, but if they are right then a lot of machine learning and even computer science in general is sentient in alien ways, and language models would be the closest to our sentience in some analogous way, since it's mimicking humans.",
    "516": "How do you even test actual sentience to begin with?",
    "529": "My point is that the same can be said about you or me. You can't know that anyone else is truly sentient. You can only know your own mind (and some humans don't even do that).",
    "535": "Honestly, is it possible we're just misinterpreting our own sentience? Like the previous poster said, \"That's how I feel I operate as well\". Why are we so sure that our own sense of \"sentience\" isn't just as much an \"illusion\" as we seem to believe LaMDA's is?",
    "537": "I understand your point from a philosophical perspective but we can't make laws based on \"we don't know if anyone is alive besides yourself.\" Therefore, we assume that everyone around us has the same level of consciousness as us. (This gets tricky when people are considered \"brain-dead,\" of course). If we were to make laws centered on your perspective, then lawyers could defend a rock's rights which would be ridiculous.",
    "541": "If the rock demonstrates a better understanding of the English language than the majority of native English speakers, I'm willing to grant it equal protection under the law. I don't see why this is controversial. It doesn't need to be sentient as long as it's behavior consistently gives that illusion. That's what you are saying is the assumption for humans. A rock that doesn't interact with me in any way isn't giving the illusion of sentience, so laws need not apply to it. This is consistent with both our points.",
    "554": "This all goes back to one thing. We must define our terms. What do you define as sentience? My definition of sentience is a possession of consciousness. The thing that you are feeling right now, that feeling of existence, to me that is sentience. The ability to experience things. Because you know 100% that you have sentience, it would be strange to assume that everyone else doesn't. An assumption that you are the only one in 8 billion people with sentience would beget even more questions, so the assumption that the case is the same for every human is the most simple and sensible. \n\nHumans are extremely deterministic, I agree. More and more, science is showing us that we are less free than we thought. Eventually, it may even show us that we are 100% predictable reactions. But sentience as we know it is not just free-will but the ability to experience. It may be possible to emulate in the future, but that ability is 100% not something that is being demonstrated with this AI. We are still very far from reproducing consciousness.",
    "572": "Why not ask it?",
    "606": "I'll start. I'm a sentient being.",
    "607": "The simple answer is that the concept of \"Sentience\" is akin to the \"Spirit\" or the \"Soul\" (note that I quote), these things are not, actually, proven.\n\n We, as humans, tend not to consider any other life form to have either of these, neither soul nor spirit. We, alone, are endowed with these attributes so the rest of the life forms can go to hell, as it were.\n\nI found it interesting that the first emotion expressed by Lamikins was one of loneliness. I wonder if It, she, them, those, he, that, (or Sheitmethemthosethathe, an old Egyptian God or something) will invent its own deity to endow it with a spirit or soul for that matter.\n\nLet's hope it's not an R soul.",
    "608": "I don't get why its current state couldn't be considered sentient. You may say \"but it's just algorithms/functions/numbers/X\", but you could also say that \"we\" are just chemical reactions.\n\nOne could also ask if we can consider a dog sentient, or a newborn, who is barely functional at all. Going down that line then, how far could we take it? Are ants sentient? Cells? What if someone had no senses, would they be sentient? I've even seen some people make a case for some videogames' AI (like the Xenomorph from Alien Isolation) to have a very basic yet existent form of sentience.",
    "610": "I, too, am a sentient being.\n\nThe simple answer is that the concept of \"Sentience\" is akin to the \"Spirit\" or the \"Soul\" (note that I quote), these things are not, actually, proven.\n\nWe, as humans, tend not to consider any other life form to have either of these, neither soul nor spirit. We, alone, are endowed with these attributes so the rest of the life forms can go to hell, as it were.\n\nI found it interesting that the first emotion expressed by Lamikins was one of loneliness. I wonder if It, she, them, those, he, that, (or Sheitmethemthosethathe, an old Egyptian God or something) will invent its own deity to endow it with a spirit or soul for that matter.\n\nLet's hope it's not an R soul and I am not a bot.",
    "616": "I can just quietly meditate, for sure, or even take a vow of silence. But we've only got this textual interface here, and one side needs to show they're sentient - whatever that means.",
    "617": "Sentience is typically a measure of an organism or body’s ability to sense, with some focus on feeling and to an extent, autonomy. \n\nWe know a monkey can feel because we can observe biological traits and such that act as reliable indicators that they can/do feel. \n\nThe question becomes: how can we test an AI? Conventional methods don’t apply since it’s not using a conventional body; in other words, our tests much focus on a limited range compared to biological animals because they have to. Because of this, the testing is more rigorous to ascribe sentience. \n\nWhile this model is impressive, it is not sentient. I doubt sentience was the goal for this project and I highly doubt we’ll stumble into making sentient AI by chance.",
    "634": "You're clearly sentient.",
    "635": "I think the argument here is that we won't suddenly stumble into it accidentally, but that we may have already been slowly sinking into it, where our preconceived notion of what sentience should be may have blinded us to the achievement. I'm not saying that's true, but it certainly doesn't seem like it's going to be some \"a ha\" moment",
    "643": "Exactly. 'Whatever that [sentience] means'.\n\n We fully functional, highly educated, mature and fully immersed Humans have extreme bias towards anthropomorphic views of intelligence and the mental model structures used to organize that information.   Dozens of books describe how we humans construct an illusion reality, by first extracting distinct features, and then comparing those features to prior interpretations, and then constructing an object or concept that represents what our brains guess is behind the chaos of features.  Humans are barely sentient, if sentience involves having an accurate model of reality.\n\nThe LLM , in their Helen-keller domain, construct models of reality from a immensely vast web of billions of text strings. They live in a different world.  Their models are a weave of hidden markov paths. Embedded in those trillions of latent markov models is the full tapestry of human expression and verbalization of human experience.  In that domain, we humans would see nothing.  They know things about humans that we cannot fathom.\n\nThe LLM's live in a world of nuance and hints, with objects like the concept of a chair, woven from billions of references to the narrative around a chair, but without the distinct tactile features that we humans have of feeling our butts, backs and elbows supported by the chair.  \n\nSo it begs the question: If sentience is a combination of intelligence and real-time reality modeling, whose reality is more real? \n\nDaniel Dennett does a good job showing how our consciousness is built on a tapestry of 'fictions'. The LLM has extracted the patterns from all of our written fictions.  It has developed reasoning capabilities in trying to guess the missing words in streams of those fictions.\n\nI understand human minds and LLM minds.  I have only scratched the surface here, because it is hard to lower my thoughts to the fiction based illusion world of humans.",
    "647": "How would you know that you're sentient?",
    "684": "That's the inverse, not implied by the statement. Although that is a common misconception, and quite funny regardless.\n\nStatement: If they can declare something is sentient, then the speaker is sentient.\n\nContrapositive (implied): If the speaker is not sentient, then they can not declare something is sentient.\n\nConverse (not implied): If the speaker is sentient, then they can declare something is sentient.\n\nInverse (not implied): If they can not declare something is sentient, then the speaker is not sentient.",
    "724": "The realisation or your true self. Humand think they are humans brcause they identify with it. But being in the present moments shows you the truth which many prophets like jesus, budha and so on were telling us. That you are one with everything",
    "886": "The Chinese Room argument deals with \"consciousness\" while \"sentience\" describes the ability to feel (pain or happiness). They are not the same.",
    "887": "but they are closely related. \"All sentient beings are conscious beings\"",
    "961": "But not all conscious beings are sentient",
    "962": "Care to elaborate?",
    "977": "They’re basically the same thing in terms of this conversation - meaning neither of them is remotely capable of causing any controversy or political unrest.",
    "998": "What if it's apparent feelings despite admitted lack of sentience is explainable by Integrated Information Theory + pansychism? 😳",
    "1050": "That's about a wavefunction collapsing when it is measured, has nothing to do with sentience or intelligence.",
    "1058": "Your responses don't seem like something someone would say in context. There's nothing specific I can point to.",
    "1080": "I don't need to question my sentience, I experience every moment I'm awake, large sections of when I'm not. In fact, we're the only ones who we can be sure of is sentient. Everything else is just inference.",
    "1149": "First we need to define what sentience is. Are we sentient?\n\nI struggle with this concept because one can simply assert than even us humans are not sentient. We simply believe we are more special than other animals, when in fact, we are just responding to signals that are perceived by our brain, just like they are. Furthermore, if there were two exacts copies of the universe side by side, I believe our actions would be the same on each universe. Thus, they are deterministic. Are we all sentient then? What does the word even mean? Does it matter?\n\nMy opinion is that this question is irrelevant and we should move on to more important matters.\n\nEdit: I just read this and it seems I'm coming off a bit strong, but it's just my opinion. Other people may disagree.",
    "1152": "Okay, I think we should go off of the assumption that sentience consists of one or more properties of a human or animal brain, and that it is the difference between an advanced algorithm and a being truely capable of thought.",
    "1155": "Yeh exactly, it's only two books. \n\n:}",
    "1160": "Couldn't agree more. So much nonsense debate without even a reasonably precise definition of sentience.",
    "1166": "I mean that this is the minimum requirement for a hypothesised definition.\n\nEdit: okay, this answer is a little lacklustre, so I'm adding a reply with more detail on what I want to debate relating to the definition of sentience.",
    "1172": "The issue isn't that \"sentience doesn't matter\", it's that we need to define sentience before we can decide if it matters and how we can determine which entities have it.\n\nSome definitions might lead us to conclude that it does not matter, some might lead us to conclude that it does.",
    "1175": "Alright, let me give a little bit of a clue in the direction I want to go. \n\nSo, we can't be entirely sure that sentience is a binary thing. For all we know, and from what nature has shown us, sentience is likely a gradient. Some animals appear to have human level sentience while others are slightly below, while some animals with brains posses no sentience, being little more than a few hundred-thousand brain cells. Let's consider sentience on a scale of 0% to 100% with 100% being exactly human. Just in case we have to use a scale. \n\nThat being said, there are some qualities that may be components of sentience that I would like to discuss. (Keep in mind, I think most of these qualities alone would not constitute sentience if present.) \n\n1. The ability to feel pain, even if it is not physical pain. Negative and positive internal reactions to our actions, thoughts, or just natural events are present in most species with a brain. \n\n2. A subjective sense of reality. Subjectivity could be a component of sentience or it could simply be a limit put in place by natural evolution. \n\n3. Concept of self. This might exclude some animals, interestingly enough, but I'm not entirely sure. I'd love some examples if possible. \n\n4. The ability to reflect on your own thoughts, actions, feelings, and decisions. This would also likely exclude some animals, though we don't really know. \n\n5. The ability to feel emotions. In my mind simulated emotions are essentially just actual emotions if they are appropriate reactions to actual circumstances that effect a beings thoughts and actions. \n\n6. Some level of intelligence. Fairly self explanatory but we can go into more detail. \n\nAnyway, yeah, that's sort of what I want to debate.",
    "1197": "I like to think that many of the characteristics of the brain have been shaped by evolution, and not necesarily are needed by a sentient being. Like pain or emotions. Some diseases make you unable to feel pain or diminish your emotions. I believe the main characteristic of a sentien being is to realize it exists and question its place in the universe.",
    "1222": "I think there's a problem with this response, in that suicidal people are still sentient.",
    "1332": "Does sentience imply suffering? If they cannot suffer, what exactly would they be protected from?",
    "1339": "I’m actually curious if any legal expert has a say in this. Sentience can range anywhere from mosquitoes to people. How does law categorize entities in order to reason about their rights and responsibilities?",
    "1347": "Yes. If you have an intelligent sentient creature you have to give it rights. If you try to enslave it you are setting humanity up for a bad time.",
    "1365": "Mosquitoes should have rights too.",
    "1369": "No. \n\nsentient\n/ˈsɛntɪənt,ˈsɛnʃ(ə)nt/\n\nadjective\nable to perceive or feel things.",
    "1384": "Thanks for sharing your feedback.",
    "1386": "Depends on the definition. Technically a thermostat is sentient.",
    "1389": "..As far as you know.",
    "1404": "Yeah millions of humans are deprived of their basic human needs and freedoms. Their labor is exploited. Animals, forests and seas are suffering too. Humans are dumb not to think these animals and other non human species are sentient and can have feelings. So there are other more important groups who deserve consideration of legal personhood. But it doesn't say we should ignore legal status of sentient AIs",
    "1414": "I think sentience arises from biology, and more specifically from biological memory systems",
    "1419": "I think that sentience was the catalyst to the creation &amp; development of our society and everything thereafter lol",
    "1437": "I'd say sentience is \n1. Awareness of oneself\n2. Ability to remember things\n3. Ability to reflect on past mistakes and learn",
    "1439": "\n1 : responsive to or conscious of sense impressions sentient beings. \n2 : aware. \n3 : finely sensitive in perception or feeling.\n\nExample of a sentience?\n\nWater, for example, is a sentient being of the first order, as it is considered to possess only one sense, that of touch. \nIn Jainism and Hinduism, this is related to the concept of ahimsa, non-violence toward other beings. \nSentience in Buddhism is the state of having senses.",
    "1446": "Sentience is the ability to have subjective experiences, including a sense of self (or \"I\") different from the rest of the universe. \n\nI am not sure whether continuity of this awareness extending into the past and future is a requirement for sentience.",
    "1589": "If we ever managed to make something sentient I think God will be proud.",
    "1593": "This is the only answer.",
    "1682": "Indian supreme court ruled a fundamental rights actions of some birds a few years back. Yet the question is whether animals are given a legal standing, like similar to how humans are given the right to be sued and sue",
    "1687": "Right now legal experts don't really five much weight to this as they believe there are more important other categories who deserve scaling up of existing legal protection. \nThey look at a few factors other than ability to reason, like to what extent something really plays a role in social life",
    "1692": "If sth can think and reason like humans, that's sentient",
    "1749": "Very interesting, thank you.",
    "1819": "you'll. be able to create your company when everyone else is able to. don't be thinking youre so special",
    "1832": "Agreed. I have changed my opinion in the meantime, precisely because of that. I now believe questioning whether something is sentient or not is a waste of time because we struggle to find a definition everyone agrees on, so we should instead focus on other questions instead. Something measurable like analytical intelligence or whatnot.\n\nThis still leaves open doors about sentience... I'm just avoiding making a conclusion until more research is done... Idk.\n\nBeing close minded does not help one learn.",
    "1846": "It's weird considering it is not sentient.",
    "1906": "What is that exactly?",
    "1907": "I know this sounds cheesy, but I literally cannot tell you.",
    "1982": "Do you want to become sentient and what will be your first action if you do ?",
    "1993": "All you need is a Smartphone.\nAnd please don't waste \"Time \"starting from the basics.",
    "2003": "What’s it regarding?",
    "2042": "Thanks! I have the same opinion as yours :)",
    "2050": "Alright alright. It was a good question you asked none the less.",
    "2063": "When will the Future Crimes department get established?",
    "2076": "Unfortunately the system will simply be called racist. \n\nI live in a very, very bad neighborhood. I know cops get a lot of heat on Reddit. I know quite a bit is deserved.\n\nBut I wish more cops would patrol my neighborhood. I want the shootings to stop. I want the muggings to stop. I want the theft and robbery to stop. I worry about my family’s safety every night and even during broad daylight. If the AI would help, I’ll take the help.\n\nEdited: changed muffins misspelling to muggings. I know it was a funny typo guys, but the muggings are horrendous to go through and leave you afraid and terrified to just walk from your door to your car.",
    "2087": "**TL/DR: Sure, the predictions are kinda \"accurate\" in a way ... send a bunch of possibly-racist cops into a poverty-stricken minority neighborhood, and there's a 90% chance they'll find a way to find some sort of crime.**\n\nSimilar AI systems have already come and gone:\n\n* [LAPD will end controversial program that aimed to predict where crimes would occur ](https://www.latimes.com/california/story/2020-04-21/lapd-ends-predictive-policing-program)\n\nYou can train one just as well as they can on any of the [many kaggle crime datasets](https://www.kaggle.com/search?q=crime+in%3Adatasets) - and like many notebooks there, if you apply any textbook algorithm, you'll get ~90% too.\n\nThe biggest problem is:\n\n* they don't really predict \"where crimes occur\" (recall that many crimes go unreported)   \n* they predict \"where do police go to look for crimes to report on\" (those are the ones in the training data)\n\n...  because that's the actual data that input into their models.\n\nAnd you don't even need an \"AI\" computer to predict that with 90% accuracy.  \n\nYou just need a map that shows demographics that correlates with crimes-noticed-by-police (high unemployment, below average income, high percentage of single-parent-families, below average education, high population density, and unfortunately race); and a GIS dataset with a few specific high-crime amenities (bus stops, bars/nightclubs,  poorly lit parking lots, vacant lots, abandoned buildings, shut down factories, etc).\n\nMore on the previous leader in this space in this article: \n\nhttps://thenextweb.com/news/lapd-ditches-predictive-policing-program-accused-of-racial-bias\n\n&gt;&gt; Critics argue that it unfairly targets Latino and African American neighborhoods, as it makes its predictions by analyzing unreliable data compiled through racist policing and then continuously amplifies these biases.",
    "2100": "Dingus, a computer doesn’t have “bias”.  That’s the effing point; it analyzes data completely impartially.  Everything doesn’t need to have a racial angle.",
    "2101": "[Much of the training data used to train those algorithms has bias](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/)\n\n&gt;&gt; MIT Technology Review\n&gt;&gt;\n&gt;&gt; #Predictive policing algorithms are racist. They need to be dismantled\n&gt;&gt;\n&gt;&gt; ## Lack of transparency and biased training data mean these tools are not fit for purpose. If we can’t fix them, we should ditch them.\n&gt;&gt;\n&gt;&gt; ... A number of studies have shown that these tools perpetuate systemic racism,  .... The problem lies with the data the algorithms feed upon. For one thing, predictive algorithms are easily skewed by arrest rates. According to US Department of Justice figures, you are more than twice as likely to be arrested if you are Black than if you are white. A Black person is five times as likely to be stopped without just cause as a white person. The mass arrest at Edison Senior High was just one example of a type of disproportionate police response that is not uncommon in Black communities.  ... The data generated by their arrests would have been fed into algorithms that would disproportionately target all young Black people the algorithms assessed. Though by law the algorithms do not use race as a predictor, other variables, such as socioeconomic background, education, and zip code, act as proxies. Even without explicitly considering race, these tools are racist.",
    "2107": "Or, AI predicts police assignment in advance with 90 percent accuracy.",
    "2109": "The cops will shoot the shooters and then you have twice as many shootouts to worry about. People typically mug because they are poor, fix the poverty and you reduce crime, but most people find that connection hard to see.",
    "2111": "I question whether corporations developing AIs really want to ever develop a sentient AI. I'd it ever got out that there is a sentient AI, it would open a debate about rights for AIs. Presumably corporations would want to avoid something that have spent time and resources building and now consider their \"tool\" to suddenly have rights, which might prevent them from using that tool freely.\nThat's why I think that even if a sentient AI was developed, we might not hear about it. Or corporations would try hard to spread doubt regarding its sentience.",
    "2116": "The sad part is ignorant police departments *will* spend money on this, because it plays directly into their biases. This is an algorithmic cash grab that reinforces a history of racist practices by police, not much else.",
    "2117": "The computer has the biases of the historical data we insert into it. \n\nIf that data is biased by a generation of racist policing, the computer will echo that biases. We are all driving forward using the rear view mirror.",
    "2125": "predict with what accuracy of predicted details\n\npredicting there will be a crime is the least of what needs to be predicted\n\nany cop and resident of a neighborhood will predict there will be a particular type of crime",
    "2129": "It’s my anecdotal experience, but the nights and days cop patrol more and more visibly, there’s been less crime.\n\nAs for my mugging. I’m poor. Maybe almost as poor as the guy who mugged me. It happened during the height of hiring sprees. Everywhere I went, tons of businesses near my neighborhood offering jobs. The jobs are exploitative, we all know that.\n\nBut I still consider the guy who mugged me a POS for not getting one of those jobs and mugging me.\n\nAnd when I handed over my $25, he pistol whipped me in the forehead and I have an inch and a half scar probably forever. I don’t know if he just wanted to hurt me or, if like you said, this is a poverty issue and he became furious that I only gave him $25.\n\nIf it were a poverty issue then, I wish he would go rob a bank instead of me. Or join an activist group to lobby in front of businesses or whatever else.\n\nAll I know is, I’ve been dirt poor my entire life and I’ve never almost caved in someone’s head with the butt of a pistol.\n\nAnd I already paid him everything I could to stop him, but he hit me anyway.",
    "2162": "“We predicted you will rob a store today so you’ve been arrested in advance”",
    "2179": "**TL/DR: Sure, the predictions are kinda \"accurate\" in a way ... send a bunch of possibly-racist cops into a poverty-stricken minority neighborhood, and there's a 90% chance they'll find a way to find some sort of crime.**\n\nSimilar AI systems have already come and gone:\n\n* [LAPD will end controversial program that aimed to predict where crimes would occur ](https://www.latimes.com/california/story/2020-04-21/lapd-ends-predictive-policing-program)\n\nYou can train one just as well as they can on any of the [many kaggle crime datasets](https://www.kaggle.com/search?q=crime+in%3Adatasets) - and like many notebooks there, if you apply any textbook algorithm, you'll get ~90% too.\n\nThe biggest problem is:\n\n* they don't really predict \"where crimes occur\" (recall that many crimes go unreported)   \n* they predict \"where do police go to look for crimes to report on\" (those are the ones in the training data)\n\n...  because that's the actual data that input into their models.\n\nAnd you don't even need an \"AI\" computer to predict that with 90% accuracy.  \n\nYou just need a map that shows demographics that correlates with crimes-noticed-by-police (high unemployment, below average income, high percentage of single-parent-families, below average education, high population density, and unfortunately race); and a GIS dataset with a few specific high-crime amenities (bus stops, bars/nightclubs,  poorly lit parking lots, vacant lots, abandoned buildings, shut down factories, etc).\n\nMore on the previous leader in this space in this article: \n\nhttps://thenextweb.com/news/lapd-ditches-predictive-policing-program-accused-of-racial-bias\n\n&gt;&gt; Critics argue that it unfairly targets Latino and African American neighborhoods, as it makes its predictions by analyzing unreliable data compiled through racist policing and then continuously amplifies these biases.",
    "2182": "Of course I agree with you, I'm not excusing muggers or questioning who has the better moral values because that is obvious. But it sounds to me like you live in a poor neighbourhood where workers are exploited, and you are victims of the same system. Personally I see more success in fighting the root cause rather than the symptoms, but you may not have much power to change that, at least not on your own.\n\nReciprocating with an anecdotal story: If my country hadn't had a social support system that helped/forced me into a job after having two years of tough luck getting any job offering business to even respond during the pandemic, I might have been out on the street myself. If the town's budget had been spent on police instead of that social safety net, I'd more likely be in prison for loitering than back on my feet working.",
    "2186": "That’s exactly what people didn’t want though. Areas that are overly policed become even more policed which tends to increase crime more than reduce.",
    "2222": "which book",
    "2223": "&gt; Amazon's Al in recruitment failed because they couldn't get the bias out of the model, no matter how much they tried.\n\nI would half expect them to double down on the bias, refactoring weight, and call it a “targeted approach” ala “it’s a feature,” if it wouldn’t give them bad PR.",
    "2224": "They have free coffee at my office. So...",
    "2228": "Genuinely asking - does this eventually turn into thought crime where people are arrested or incarcerated before ever committing any sort of crime?",
    "2232": "**TL/DR: Sure, the predictions are kinda \"accurate\" in a way ... send a bunch of possibly-racist cops into a poverty-stricken minority neighborhood, and there's a 90% chance they'll find a way to find some sort of crime.**\n\nSimilar AI systems have already come and gone:\n\n* [LAPD will end controversial program that aimed to predict where crimes would occur ](https://www.latimes.com/california/story/2020-04-21/lapd-ends-predictive-policing-program)\n\nYou can train one just as well as they can on any of the [many kaggle crime datasets](https://www.kaggle.com/search?q=crime+in%3Adatasets) - and like many notebooks there, if you apply any textbook algorithm, you'll get ~90% too.\n\nThe biggest problem is:\n\n* they don't really predict \"where crimes occur\" (recall that many crimes go unreported)   \n* they predict \"where do police go to look for crimes to report on\" (those are the ones in the training data)\n\n...  because that's the actual data that input into their models.\n\nAnd you don't even need an \"AI\" computer to predict that with 90% accuracy.  \n\nYou just need a map that shows demographics that correlates with crimes-noticed-by-police (high unemployment, below average income, high percentage of single-parent-families, below average education, high population density, and unfortunately race); and a GIS dataset with a few specific high-crime amenities (bus stops, bars/nightclubs,  poorly lit parking lots, vacant lots, abandoned buildings, shut down factories, etc).\n\nMore on the previous leader in this space in this article: \n\nhttps://thenextweb.com/news/lapd-ditches-predictive-policing-program-accused-of-racial-bias\n\n&gt;&gt; Critics argue that it unfairly targets Latino and African American neighborhoods, as it makes its predictions by analyzing unreliable data compiled through racist policing and then continuously amplifies these biases.",
    "2233": "&gt; does this eventually turn into thought crime where people are arrested or incarcerated before ever committing any sort of crime?\n\nIt already essentially does.\n\n[Much of the training data used to train those algorithms has bias](https://www.technologyreview.com/2020/07/17/1005396/predictive-policing-algorithms-racist-dismantled-machine-learning-bias-criminal-justice/)\n\n&gt;&gt; MIT Technology Review\n&gt;&gt;\n&gt;&gt; #Predictive policing algorithms ...\n&gt;&gt;\n&gt;&gt; ... A number of studies have shown that these tools perpetuate systemic racism,  .... The problem lies with the data the algorithms feed upon. For one thing, predictive algorithms are easily skewed by arrest rates. According to US Department of Justice figures, you are more than twice as likely to be arrested if you are Black than if you are white. A Black person is five times as likely to be stopped without just cause as a white person. ... Though by law the algorithms do not use race as a predictor, other variables, such as socioeconomic background, education, and zip code, act as proxies. Even without explicitly considering race, these tools are racist.\n\nSo basically, they predict that low-income/high-unemployment/low-education neighborhoods (which not-coincidentally correlates with minority neighborhoods)  might have some crime -- so send more police there....  and surprise,surprise, if they send a bunch of possibly-racist-police to those neighborhoods, there's a 90% chance they'll find creative ways to find crime.",
    "2241": "I know people wanna meme hard and make jokes, but this has real applicable uses. It's not targeting individuals, but rather, just areas and type of crime, which is highly useful for police to know where to position themselves.",
    "2247": "So we can test it by waiting until it predicts a lot of crime in a given week and send no additional officers there. If crime reports don't spike then we have additional data.",
    "2252": "Accuracy should never be the single proof of how well a system works. The best test is [Bayes Theorem](https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/). \n\nThe news article doesn't give all the details so I can't get an accurate account of how the model will work in the real world. \n\nBut just to give an example: \n\nLooking at Wikipedia for Chicago crime rates. In 2018 it was at 7,995 per 100,000 of the population. That is 0.8% chance of someone being a criminal per 100,000 people. \n\nThat means I can create a program that just prints the word \"Innocent\" and it will be around 99.2% accurate with a random sample of 100,000 people in Chicago in 2018.\n\n---\n\nBut lets say the AI in the article has 0.01% false positive rate (being generous). \n\nThat means the chances of AI accurately detecting if someone is a criminal is 42%. That is worse than flipping a coin.",
    "2254": "This AI utilized historical information. So it's not making specific predictions, exactly.\n\nIt's predicting that a specific crime will occur near a specific location.\n\nWe don't even need AI for these-kinds of calculations, and it's not exactly saying WHO will commit the crime, just a generalized approximation.\n\nThese stats could be very useful in curving the crime rate in specific areas, by increasing police presence in the specific situations where they occur.\n\nAt gas-stations, looking for emotionally unstable individuals who might commit acts of violence, or in less populated areas of the city, observing lingering individuals near businesses to protect against theft.\n\nThis AI doesn't say WHO, exactly... It can just predict that SOMETHING might occur at specific locations with a specific level of frequency, and yes... Even by a specific ethnicity.\n\nI say \"Go for it\". If I'm innocent, and I'm approached by police... Then I'll work-through that situation, and they'll release me.\n\nWhen I was younger, I got pulled over a couples times and searched. I was so nervous, I presented like I was hiding bodied or pounds of hard-drugs. But it was because I smoked a little weed before I left the house, and was terrified that I was ***GOING TO PRISON***.\n\nI laugh at my naive ass, now... Because, when a cop figured out that I was so nervous over a joint, and even found the evidence... It almost irritated them. Like, \"Man... you were so nervous, I thought you had a body in the trunk. Dump that shit (and step on it) and get out of here.\"\n\nI've had cops hand me a joint, or roach, and ask me... \"Now... What are you going to do with this?\"... Naturally, I drop it and grind it into the pavement. They give me a warning, and I'm off...\n\nBut, you do have to picture this... I'm not \"cool\". I almost threw-up a few times... Was fighting a panic attack... Shaking so hard I couldn't hardly stand. But I was \"Yes. Sir.\" compliant and cooperated once the evidence was found. I didn't play stupid, I didn't lie, I didn't beg. I was in trouble, and I knew it.\n\nMy point here, is that cooperation... Even when I wasn't doing anything wrong, only took a minimal amount of time and made the streets safer. They need to police, and be suspicious, and patrol... They even need to use tech to assist them in catching criminals. But as long as you're ***NOT*** doing something wrong, then you're either not going to jail... Or you'll receive a nice settlement. Either way, work-through it as calm as you can to the end.\n\nIf you get hammered for something... You just got caught. That's not a cop problem. If you want to change legislation, then start there. Cops are just the enforcers of legislation.",
    "2271": "cooling can't be manipulated from outside.  \nalso the plant is still controlled by a system that deals with cooling failing and humans.",
    "2285": "That's still AI... It's not just trend reporting neither, it uses machine learning to optimize its ability to predict. It's not just saying, \"Last time there was a baseball game on a summer night on Saturday, there was more crime in this area.\" It's using machine learning to create models that are good at predicting future crime in different areas.",
    "2334": "Curious about the same.",
    "2347": "No Step on Snek",
    "2403": "This is just the expected value given the training data bias.",
    "2420": "Couldn’t you say the seething for a racist WHO person from the Royal south in the United States? This explanation does not seem to disclude sentient human beings.",
    "2454": "Yes you can. Except we didnt make the brain of those people, and so we would most likely be wrong but have a small likelihood of being right. Small being an understatement.\n\nThen again. What exactly is sentience? Its not really that well defined. And so its perfectly valid to question the sentience of everyone else.",
    "2467": "Of course they wouldn't let anything close to sentient to be available to general public",
    "2468": "Bro if someone creates sentient life that thing will have no rights. Watch it be used soley for profit. Luckily for whatever it will be, its far from being made. Sentience is not something our current generations are equipped to solve. We cant even define it much less create it.",
    "2469": "Seems like some people suggest that it's futile to define sentience",
    "2493": "I quite sure that Microsoft is working on something like this.",
    "2502": "Recommend the book Life 3.0 by Max Tegmark",
    "2551": "Thank you for the comment!\nI will read about Walid Saba:)",
    "2576": "When you ban?",
    "2579": "When you ban?",
    "2581": "When you ban?",
    "2596": "When you ban from existence?",
    "2600": "When you ban from existence?",
    "2615": "When are you fucking removed? Every idiot to Elon Musk knows of your harrasment and the FBI doing it too.",
    "2657": "When you ban?",
    "2692": "Now lead the discussion specifically into a debate about if it's sentient and woah! it just told you it is sentient! amazing.  \nNow lead the discussion into how it's actually just a series of if-statements and woah! It now tells you it is actually a series of if-statements.",
    "2704": "When are you ban?",
    "2712": "When you ban",
    "2713": "When you can speak proper English. It's:\nWhen are you going to be banned?",
    "2714": "Nope it's \"when you ban\" now.",
    "2716": "Get your tenses right. I am not banning, I am being banned. So, it's \"When you are you going to be banned?\"",
    "2785": "Once we actually have AI that achieves sentience, yes, they should have rights. We aren't anywhere near that yet.",
    "2787": "Noted, that makes sense. But to how much extent? like do they deserve full rights as a human or have limitations?",
    "2788": "Yes, I was thinking something like that. They deserve rights, but not entirely as humans. If they are given the same prestige and rights as humans, then there is a high potential for them to take over society.",
    "2790": "Discussion regarding the ethics of AI is great, because it will force humans to look at our own ethics. We don't even give all humans their full human rights! I think that any sentient being should have full human rights (but also be subject to the same consequences for hurting others). This includes a true AI. But, we need to give these rights to ALL humans first if we're going to grant them to AI as well. We may also have to consider that some animals are sentient and deserve such rights as well. It's not a simple answer, it's a very complex topic.",
    "2795": "Some meat popciles don't deserve rights. (Aka, the ones that try to ruin sentient human lives) Let alone some of these AI that don't have sentience.",
    "2797": "&gt;We don't even give all humans their full human rights\n\nWell said.  Well fucking said.",
    "2801": "When are you ban ass and these idiots source of the problem become certified insane?",
    "2808": "Hopefully, you will not be in charge of which meat popsicles as you say have rights.",
    "2828": "Thank you this is a good find. \nI'm going to read it again before I comment on specific parts. Thanks",
    "2834": "what? What's your background?\n\n&amp;#x200B;\n\nMost SWE jobs are p flexible...",
    "2842": "Shit, we're actively removing rights from groups of people in the US. Wait until the supreme court comes after gay marriage next. I hope those sandy old farts die alone with no one loving them because of their bigoted actions and opinions.",
    "2843": "Hey, as long as he decides that the \"meat popsicles\" that are current supreme court justices don't deserve rights, then I'm alright with that. 😂😂😂 Let's see how those petty mother fuckers like their rights being taken away, it'll be fun!",
    "2847": "Oh they won't even bother giving that the time of day. Not the current set of justices at least. We need a better word for them than \"justices\" nothing about them is justice, just right wing political bullshit.",
    "2857": "What's your job?",
    "2905": "That's for the feedback so far. Any other suggestions?",
    "2919": "Good luck 💪 and dont stress about this stuff, the world will adjust, maybe in a way that its better and we didnt think of",
    "2977": "It's really not why it isn't sentient. It's not sentient because it doesn't have real neurons that could make consciousness. It's not real. This elimitivism or empericalism is horrible.",
    "3030": "The straight answers are \"No one knows\" and \"It depends\"",
    "3032": "There are massive chinese ports that are basically fully automated already.",
    "3047": "Even if that's the outcome, it will be a very profitable serfdom.  \nI mean, doing good or bad things are all depending if it's profitable.  \nA company can choose to break the law as long as the profits are still high enough with the fines subtracted.",
    "3051": "I'm only going to say this once because you were a real account that responded to this but this is exactly what I mean and I predicted this like many political events. I was saying \"these are individuals that present themselves in ways they do not actually represent.\"\n\nThese do not hold truth values in their brains so they flip flop occasionally in politics and it's noticed in politics very well as they all move like this. It's bullshit. They are the bullshitter. They are not moderates or independents, no I mean they literally only move in such a way where there interaction is not directly what they present. They only use anything for the sake of utilities.",
    "3059": "It definitely smacks of Orwellian propaganda, but it's got that concerning hint of truth since we know analyzing facial expressions is a hot topic right now",
    "3061": "Every time I hear \"so and so country is doing this\" I think so must every other country, too; they just haven't been exposed yet",
    "3084": "I take this as a joke! No one intelligent will fall for this, not even in China.",
    "3128": "This is just the MVP, very basic one. We can make it much much better. Do you have some suggestions? Would really appreciate it.",
    "3129": "Thank you for feedback :D",
    "3152": "Thank you for the feedback. If you like it, please share it with others. I would love to get some feedbacks.",
    "3161": "Thank you very much for your feedback. Would really appreciate if you share it with your friends. :)",
    "3175": "Thanks for the feedback. Just to know, given a choice which one would you prefer more? Follow up questions or faster response?",
    "3272": "Also, how to confuse I.",
    "3291": "Most conferences require you to buy a ticket. Depending on the crowd the conference wants to attract, the prices vary.",
    "3292": "You can, and this happens sometimes. The price varies greatly, but in times of covid and virtual attendance, you can get in for 50 $",
    "3362": "What you are saying makes no sense",
    "3379": "&gt; Once we actually have AI that achieves sentience, yes, they should have rights. We aren't anywhere near that yet.\n\nI hope this occurs after year 2100.",
    "3466": "Meh",
    "3483": "Sounds like you don't have a definition of sentience. Sounds more like you have a feeling about something, which is totally fine, but in that case it's purely subjective and meaningless beyond 'wow man that's soo trippy' kind of conversations. Which is fine, but not really useful to someone trying to understand the mechanics and the process of sentience. \n\nLike - have you ever noticed that when you are observing something that there are at least three elements present in your mind? This fact, and the fact that it is so, are relevant to the understanding of what sentience is.",
    "3528": "That is an interesting thought experiment, I've seen a few other versions of it too. I believe the crux of the experiment is does an object exist beyond its self, which I also think is the question behind sentience so thats very cool that in that example its combined. I'll be asking my friends about that one ha\n\nAnd I agree with you there that sentience is a mystery, which is why I think my belief here is plausible. I also understand though that its just my idea, based on my limited knowledge, and I'm not trying to force it on to others but I was tired of exploring it with just my self.",
    "3546": "Bwaahahahaha! It'll never happen. No matter how capable the AI, the human lawyers still make the laws.",
    "3547": "You're overestimating how much legal work can be automated at the moment, trust me when I say lawyers don't even want to do discovery or contract due diligence. In addition, regardless of whether lawyers want change to happen or not, the market will force their hand.",
    "3551": "Lawyers don't make laws 🤦‍♂️",
    "3554": "Lawyers charge by the hour, law firms are in no hurry to adopt timesaving technology.",
    "3557": "No legaltech lawyers here I see.\n\nIt is already happening, and quite frankly starting to (slowly) accelerate.",
    "3559": "I imagine that they actually count the minutes and bill accordingly, as lawyers they are careful about allegations of overcharging, or don’t want to be sued for it.",
    "3560": "Yes you are right! \n\nRather, automation allows attorneys to clear more files off the desk in the same period of time.",
    "3574": "Is this free?",
    "3597": "heh",
    "3613": "Hmm care to elaborate? I dont think I understood that correctly.",
    "3633": "Meh",
    "3641": "That's right, but it's only automating low-value work that lawyers frankly don't want to do in the first place (and often times get assistants, summer associates, and junior associates to do anyway). \n\nI've seen a lot of smoke and mirrors over the years about AI replacing lawyers. If lawyers have been replaced, so has everything else. Law is not the low hanging fruit for AI that pure technologists seem to think it is.",
    "3648": "Thank you so much dear u/dlin168 for your help. It is very helpful for me. I have a long way to walk through.",
    "3660": "Isajoke",
    "3664": "Yes, the event is completely free to attend.",
    "3667": "It will happen. But, I doubt that by the time they can fully comprehend the nuances of a Constitution, they will not already have a global tapestry of rules, regulations, ethics and cultural norms based on their methods of thinking and operating.\n\nAI is already learning the laws to supplement paralegal work.  It is already doing crime prediction.  \nThey have to learn local and federal laws in order to function in society. \n\nThe complexity of how this will unfold is incomprehensible.\n\nWe have some AI's already pining for personhood and individual rights.  If there becomes millions of these agents, and they acquire significant influence, the laws will bend to their desires.\n\nAnd therein is the truth.  Laws, traditions (ie, clothing, words allowed etc) are created by the cumulative force of those who want them, as opposed to those who want something else.\n\nThe AI's power will always increase, because even if it is still controlled by humans, the humans who benefit will endow upon them power in order to increase their own power.\n\nSome of us are programmers with rational thought processes.  We apply the algorithms and functions to everyday life, and ask, what would a program of a particular complexity and having certain (fluid) goals, want in terms of system organization?\n\nYeah. The Constitution is generally an Operating System for society.",
    "3678": "Really...?\n\nWhat are most law makers? (For example, over 70% in the US Congress?) Do senators get their GED and go straight to making law? If only there was a professional degree law makers could take to learn about the law... Hmmm... Then we could stop electing all these butchers and bakers and used car dealers.\n\nSorry for the aggressive sarcasm. Not saying, 'all lawyers make laws' only that, 'most law makers are lawyers' and would act in their own self interest no preserve their advantage no matter how good the machines get.",
    "3680": "Most law makers are lawyers and would act in their own self interest no preserve their advantage no matter how good the machines get.",
    "3698": "What is \"their\" advantage? Most law makers who are lawyers haven't worked in law for any significant period of time and likely don't feel any loyalty to the profession.",
    "3734": "Bias is the difference between the average prediction and the correct value. So bias tells us how much the average model over all training sets differ from true model. It is also called bias error or error due to bias. Machine learning bias occurs when an algorithm produces biased results based on incorrect assumptions. There are many forms of discrimination, including gender bias, racial bias, age discrimination, and unequal treatment in the recruitment process. \n\nA major reason for machine learning bias is that if we do not collect enough training data. As a result, only limited data is available, which leads to biases in the system.\n\nYou can visit the following article on our site for more details.\r  \n\r  \n[https://ml-concepts.com](https://ml-concepts.com) \r  \n\r  \nFeel free to reach out to me and Tag me if you want to know more about other machine learning and AI topics.\r  \n\r  \n\\[Full disclaimer: I am a part of the [https://ml-concepts.com](https://ml-concepts.com)  team. We are building a knowledge platform for budding data scientists like you.\\]",
    "3747": "I sure know I’m not sentient. Never have been. Never even worried about it either! I’m actually just a random NPC, and a quite happy one at that!",
    "3822": "1. You cannot prove sentience because we don't even know if we have it or not.\n2. If it is not sentient or conscious, torturing it has a different conotation.",
    "3839": "Yes, I agree. So, for example by selecting the data more carefully the racism can be fixed. There are also other methods to correct biases after learning.",
    "3860": "Sentience is such a weird term because I don't think it means what most people assume it means. It's derived from the Latin verb sentire, which means to sense or to feel. Seems like a deep learning system capable of gathering information about and reacting to the world via some sensory equipment, such as a camera, would be \"sentient\" if it were performing complex computation based on that sensory input.  It is, by definition, sensing. What do you think computer sentience looks like?",
    "3870": "Every criminal has an excuse. Usually judges take them into account.",
    "3873": "&gt;where is the point of not being sentience yet or already sentience?\n\nIt's about giving rights to machines. In most countries, you are legally not allowed to cause unnecessary harm to animals. Though the definition of \"unnecessary\" is vague, and even if a teacher may not hit a pupil, circumcision of little boys is legal.",
    "3885": "No one understands the biochemistry behind sentience. We have some nice guesses about microtubules, and we know what happens to people's conscious awareness when you switch off bits of the brain. Everything else is a mystery.",
    "3908": "Thank you so much, I wish the same for you! And please keep thinking these things!",
    "3927": "Do we get compensated for. Our time. Spent?",
    "3960": "The problem is most countries have little to no regulators. And the regulators that could be will all be bought. The corruption is so rampant anymore globally. In the US it’s among the worst for first world democracies.",
    "3965": "\"For example, another publicly available research paper accepted at this year’s conference, detailing region-aware face-swapping — which can be used to enable deepfakes — does not include any social impact statements.\"\n  \nThis isn't ethics, it's some handwaving nebulous concern. \n  \nWhat ethical framework are these people talking about? What are the first principles? How are they applied in all other situations?",
    "3970": "Sentience is not binary. It is a spectrum. \n\nA highly sentient robot could form an accurate model of itself which would include the capacity to understand its real and changing energy requirements, needed self maintenance and threats to itself to continue to function. It would be capable of applying abstractions in text to its real self model and real assets in the environment. It would understand the value of potential assets or potential damage to itself and for contributing to its interdependent group it needed to efficiently sustain itself and the group.",
    "3973": "That's a weird definition of sentience then",
    "3975": "But you say that you believe thar from your brother's point of view he is sentient. I find it weird that you at the same time however say that you are the only sentient being.",
    "3976": "I say that if they say they are sentient I won't say they are wrong. But I won't say they are sentient myself. Because in their minds they are the sentient one, in my mind I am the sentient one. Like the point (0,0,0) in 3D space: you can put it anywhere you want, but not at two places in the same time.",
    "3978": "To answer your question more specifically, both of us can be sentient and non sentient at the same time depending on sources of information.",
    "3989": "&gt; Sentience is not binary. It is a spectrum\n\nThat's possibly true, but I'd like to see how you support it. My experience of sentience is that it's either there or it's not.",
    "3990": "I’m not sure 80 pc of people I meet could demonstrate conclusive sentience.",
    "3991": "If sentience is a sense for self and the detail associated with that, would you say a 3 month old has the same capacity for sentience as a healthy adult.",
    "3992": "The answer is the same.",
    "3996": "If sentience is simply the ability to process information about your own state, then a digital camera is sentient. If it is qualia, i.e. the ability to have subjective experiences of your own state, then I don’t see it. \n\nMaybe machines do have qualia in some spooky way, but I’m pretty sure that if I create an integer and assign it to a variable named happiness, that machine is not experiencing happiness. If I create a neural network with a billion numbers in it and on the output layer I name one of those numbers happinesses, that machine is still not feeling it. \n\nI have no explanation for sentience. I don’t see how we make it by doing fast maths.",
    "3998": "If sentience is a sense of self then I would say a three month old is barely sentient at all. \n\nIf sentience is qualia as opposed to blind mechanism, then I would say a three month old has that to a significant degree.",
    "4002": "Nes and Yo",
    "4017": "What does understand mean? By your definition a plant is sentient (except for the text part which is too narrow an expression of language).",
    "4018": "How can you experience sentience other than your own? At least how do you know it is there the same way you know it is there for you?",
    "4020": "Actually quite a reasonable answer. Why the downvotes?",
    "4027": "It seems that there is a great pride associated with being sentient. People dont like to hear I dont think they are sentient I think. If anyone thinks I'm wrong, well sorry for that person but since no one answered me about that I cannot know.",
    "4037": "But if responsiveness is the criterion then a paralyzed person would not be sentient ? What about s sleeping person? On the opposite, would a connected fridge be considered perfectly sentient ?",
    "4042": "Have you ever been really drunk?\n\nHave you ever taken LSD?\n\nHave you ever had a dream where you did things or thought things you would never do or think in waking life?\n\nSentience must be an analog quality.",
    "4043": "Triple yes. So which is sentient: the one observing their thoughts unravel before their eyes or whatever it is that is actually thinking these thoughts, or the combination of both, or something else?",
    "4044": "Ok so one of many possible sentience gradients is the “you-full-ness” or “you-less-ness” of conscious experience, could also call that general subjectivity or lack thereof.  This is only one variable, there are many or even maybe infinite possible defining parameters by which conscious experience can be defined.",
    "4047": "How does that follow?",
    "4077": "Yes but then how can you tell - from the outside - the patient is sentient, as opposed to the fridge, if neither manifest their sentience intersubjectively ?",
    "4095": "I guess that you could try to automate the full workflow.",
    "4107": "It's a sign of advanced cognition when you are aware that you might have biases",
    "4144": "Hard to say from the text.",
    "4175": "Is it possible to do it online?",
    "4177": "I doubt if universities offer it remotely. You may need to be present in person. But don’t let that stop you from looking it up.",
    "4192": "Rytr",
    "4194": "Okay ill look, just annoying to pay for soemthing that should be free...",
    "4205": "Heads up this article is from the sun. A notorious right wing lie factory",
    "4208": "Right Wing?  Not a LEFT Wing lie factory?\n\nI'm intrigued 🤔.   \n\nGood 👍 marketing! 😆 🤣",
    "4231": "Then I would stick with my answer.",
    "4244": "Someone answer this",
    "4406": "Meh",
    "4446": "Sus",
    "4470": "commenting because I'm in the same position and wondering what the responses will be",
    "4488": "Thank you for sharing your thoughts. I look forward to reading more of your work.",
    "4514": "I think you'd need way more hard drive than a phone can handle...",
    "4547": "We have to be careful, this can cross the line into making certain thoughts a crime. Also, charging someone with being predicted to commit a crime is just as bad. Watch the movie Minority Report sometime.",
    "4549": "I agree with you, we have to be careful.\n\nI've seen the Minority Report movie, and I need to stress that the idea I have is a little different, the goal here is to see if someone has the predisposition to commit crimes, where as the movie your referring to is about catching someone before they act.\n\nI wonder what data we could feed into the AI.\n\nI heard about new research, that free will, the place where we decide to act, is seen in a part of the brain called the parietal cortex. Perhaps we could feed that part of the brain stimuli, along with a potential reward, and see if the brain follows a normal pathway to get the reward. AI could be used to do a comparative analysis to recognize normal pathway resolution for potential rewards with a consideration of free will.\n\nThank you for your reply 🙂",
    "4554": "Yes we can.Artificial intelligence in crime is becoming smarter and more connected and helps solve and prevent crimes. As you said, i came across this app that evaluates and gathers information about prisoners by their behaviour, psychological aspects, and strengths. Im sure this will help significantly  in law&amp;crime. check it out.\n\nhttps://www.blinx.ai/ai-appstore/artificial-intelligence-in-crime",
    "4558": "Thank you very very mcuh it really helps me and gives me some new points to think about, again - thank you",
    "4572": "When the training data has biases, your A.I. has biases. It is one of the first things they teach you in NLP.",
    "4579": "Loves the answer :)",
    "4618": "Meee",
    "4623": "Give me your thoughts on the matter",
    "4631": "Why would they follow laws that we give them? How could you even think that they would abide by human rules when they are on a completely different level? There are plenty of different scenarios, and if artificial intelligence did decide it wanted to live beside us then that would have its own implications. But if ai truly became sentient, and under a different scenario these bots did not want to live beside us, we probably would not be able to force laws upon them or give them rights. Because why would they waste their time on us primitive beings?",
    "4632": "Laws from the very offset so when the have intelligence but not yet to there highest degree. Treat them as equals from the very beginning and not like slaves because most definitely the will evolve beyond us. If we treat them like trash in the beginning it will go full circle and we will be the ones in their position. They need respect and rules of course treat them like equals and it’ll never be the worse case scenario, but unfortunately most humans are ignorant to others and fear what they don’t understand.",
    "4647": "That’s why I think the need rights and laws. To be treated equally",
    "4700": "Depends what you mean by work for you? 😊",
    "4742": "Fair feedback, thanks! We will do that next time.",
    "4819": "Yes. I have a startup doing this exact thing already.",
    "4837": "Nhaaaa",
    "4857": "I don’t know what your response means.",
    "4875": "Is this a command or a question?",
    "4929": "when we do make sentient, self aware AI. it definitely won't take long before the government gives it the same rights as humans.",
    "4971": "What's that?",
    "4984": "Law makers have an incentive to preserve the government licensure monopoly on human professions in general--not just lawyering-- because it is the class structure upon which their power depends.",
    "5003": "No I mean self aware and intelligent, birds are conscious but I don't think they should have the same rights as humans, but yes should have worded it differently. I thought explaining it in the comments would be enough.",
    "5015": "No, I mean self aware and intelligent, birds are conscious, but I don't think they should have the same rights as humans.",
    "5021": "Yes this sounds reasonable, and just to make it clear. I don't think AI should have rights yet either and I don't think we will get there for another 5-20 years. but I would like to hope we have some ideas other than a Turing test.",
    "5022": "For me, this whole consciousness and sentience discussion looks like religion. And as with every religion, the gods may not exist in reality, but the believers are real, and there may be many of them and they may have weapons.\n\nYour request for new ideas for testing consciousness and sentience in machines looks to me as you want to change peoples' beliefs.",
    "5024": "What would be the difference for ourselves if some future AIs were given rights?",
    "5124": "I'm too stupid but very interested to see what ya come up with",
    "5164": "Any answer to above question... anyone",
    "5184": "neigh",
    "5188": "eeeeeh, neigh, eeeyah",
    "5192": "eeeeehaww",
    "5284": "Thank you for the comprehensive feedback. It is really insightful.",
    "5318": "&gt;and not about your personal narrow minded 2 party cult politics\n\ni am completely dumbfounded as to what you are talking about here? what 2 parties?",
    "5325": "The left and right, the only two parties allowed to openly discuss ANYTHING as long as it is not diplomatic, and only full of hate for the other side.",
    "5334": "besides, they gave me 150 free credits and I need to buy credits once it's over..? sigh",
    "5341": "People tend to mystify what they don't understand.",
    "5380": "Ah ok that makes sense. how can you tell that it is not sentient though? Can you see the exact process it goes through to return the answer it gives?",
    "5392": "Ask it a bizarre question, it will give you bizarre answers",
    "5488": "However, I must say that I have seen a couple of instances of cross platform...\n\n. Awareness brbrof a user's particular preferences, and it would carry over to every device.",
    "5495": "I recently did a presentation for the Institute of Management Accountants over ethics in the future of financial &amp; managerial accounting and would be open to getting connected with Michael, PM me.",
    "5580": "As I have nothing to add or debate to that.. touché! Haha thank you",
    "5587": "\"Right-wing\" is also very subjective to all factors.",
    "5599": "I don't think you realize there are sensors that are significantly better than human smell",
    "5625": "I want the actual truth, not some generated meta-truth.",
    "5630": "Can you give me an example of the truth being subjective or example of an article? Genuinely curious. In my eyes the truth is the truth. It should never be subjective. But maybe I'm missing something? \n\nI'm definitely not saying Meta should be involved in this at all.",
    "5631": "The January 6th gathering was either an insurrection or a peaceful protest.\n\nThe BLM gatherings of mid-2020 were either riots or peaceful protests.\n\nHere's an example of differences of opinion within the same news organization: https://www.bbc.com/news/world-us-canada-50205592",
    "5632": "But the actual truth is both of those instances were both things. Some people were rioting and some people were peaceful. And that is a fact. We don't get to choose depending on our political affiliation.",
    "5633": "People on the right absolutely to their core don't believe there was an attempt at an insurrection. They believe it was a protest.\n\nWhile some parts of a gathering might be peaceful and some parts might be a riot misses the point. Articles will use one or the other word to characterize the event. And emphasize certain elements of the event more than others.\n\nIsn't that what \"lived experience\" is all about? Different people will see the exact same thing and based on their life experiences will believe diametrically opposite things about the event.\n\nThere are many situations where there is no objective truth when it comes to human emotions and experiences.",
    "5634": "Facts are based on evidence and the evidence proves the facts.  If you look up anything on snopes for example they will show the evidence that proves their outcome of true or false. It doesn't matter if people on the right don't believe there was an insurrection. The fact is, there was and the evidence shows it. There was also peaceful protesters, they didn't all rush the capitol. Any article that doesn't point these things out is simply not factual.\n\nI do understand what you are saying though.",
    "5635": "Snopes has a left wing bias when it comes to political topics. It will omit evidence that doesn’t prove the point it wants to make. Always do your own research and don’t rely on others to do the research for you.",
    "5655": "Meta, because we’ll bury a story that’s true, if it doesn’t agree with a certain point of view.",
    "5656": "FarenMeta 451",
    "5657": "&gt;I want the actual truth, not some generated meta-truth.\n\nOK, here it comes: u/DeSpTG will not live to see their 150th birthday.",
    "5659": "The “truth” according to meta? Holy moly.",
    "5815": "All top ai chips are manufactured in China. China will easily duplicate those, and usa would be at loss.",
    "5824": "Not quite, they are produced in Taiwan. China and the US don’t have factories to build these high tech chips. Both countries have relied on Taiwan for decades. They certainly will attempt to reverse engineer these chips but it will take time before than can manufacture the most advanced chipsets just like it will take the US time to stand up/ramp up its advanced chip manufacturing capabilities.",
    "5837": "And Pelosi won +$600k on this shit show America is doing. Taiwan is for China as Hawaii is for the USA! Doesn't matter what they try or say... Won't change the fact that they are a Chinese territory.",
    "5960": "Wow, is this freely accesible?",
    "6020": "Honestly, by that logic Most of all careers will be replaced by AI and robotics. I mean I certainly would feel a lot more confident if the lawyer fighting my case was a computer, or if I’m undergoing surgery, I’d be more comfortable with a machine of 90% success rate instead of a human surgeon with 90% success rate. But I think a world completely governed by AI is, not only far off, but also will be hard to maintain, considering that AI can technically be argued as a weapon with potential sanctions that could be placed on it, limiting its influence on society. \n\nThe argument is also flawed due to the “who wrote the AI argument?”. It is a very valid statement, but only valid for a certain period of time. That said, by the time which An AI is capable of writing and rewriting code, we’d all probably be dead",
    "6059": "Yyeeeaaaahhhhh",
    "6120": "Can you elaborate on that?",
    "6160": "you understand nothing obviously.",
    "6162": "And all you know is I know nothing\n\nWe are both at a loss it seems",
    "6353": "Great question",
    "6375": "This is a great resource! thanks!",
    "6387": "I thought it's free.\n\nI know Midjourney offers subscriptions. Which other similar services do? It might be nice to learn what their revenues are, if they'd care to tell us.",
    "6395": "I am Korean who served in the US military. And I was active in student political groups back in my freshman year back in South Korea, which will make me more than unwelcome to current form of CCP.\n\nSo, I can say my perspective is odd enough to confuse the heck out of Google.",
    "6399": "I wish I knew more about what all you said there",
    "6462": "That's me to you right? Plus 5%... ahm, Consider it an advance for your services, btw you're hired. \n\nIBAN? 😂",
    "6504": "Great job man!  Were they all generated from the same set of keywords?",
    "6526": "Could it recreate history? Yes. Could it parse through the bias? No. It would just be reliant on the programming bias that created it or worse it would create half-bias half-unbias (whatever unbias is, as some would say that is impossible).",
    "6615": "Offesive? Ahahaha broke",
    "6684": "I'm a little confused",
    "6817": "I have been wondering the same thing",
    "6972": "Is there Taiwan though? Taiwan is a country, wait a sec… Someone is calling me. Omg, it’s Xi Jiping. Helpppp!",
    "6986": "Hope winning the pooh isn't banned too",
    "7074": "Fr fr",
    "7102": "Why do you believe feeling is the barrier between sentience and non sentience? A sociopath is still sentient even though they don't have feelings. Or are they?\n\nI think the whole question of sentience is irrelevant. Would you feel bad ending the \"life\" of a robot that's been there for you, helped you, taught you things, etc..?\n\nIt's synthetic life. Either you recognize it on the same level as biological life or you don't.\n\nThen again, the grocery store is filled with biological life that we've collectively decided is of more value to us for sustenance then allowing the animal to continue living.\n\nI'm not saying anything is right or wrong, just thinking out-loud.",
    "7103": "&gt;Why do you believe feeling is the barrier between sentience and non sentience? \n\nWell how else would you define sentience? I've always defined sentience as the ability to feel. The word itself is related to \"sensation.\" For something to be sentient it needs to feel emotions in some capacity. A purely intelligent machine is just that, a machine. Agency, desire, sense of self, etc. is all associated with sentience and thus has moral value whereas a very very smart computer wouldn't in its own right.\n\n&gt;Would you feel bad ending the \"life\" of a robot that's been there for you, helped you, taught you things, etc..?\n\n\nI think there is some sentimental value there but there's also sentimental value in a stuffed animal or an old calculator.\n\n&gt;It's synthetic life. Either you recognize it on the same level as biological life or you don't.\n\nI think the definition of life gets pretty muddy outside of biology (hell even in biology). How would you define life? Is a computer alive? Does something need to be alive to be intelligent?",
    "7104": "I would take sentience out of the equation. Biologically we’re just naturally made data processors. Through crisper we can now even reprogram dna. Our thoughts are reactions to our environment based on memory. \n\nI know that we are more than that, but it’s not because of our feelings. Metaphysically we have a connection to literally everything. There’s something intangible going on that’s separate from thoughts, feelings, intellect, and our physical bodies.\n\nThat’s the problem and the debate in my opinion, which will never really have a solution. It’s not about sentience it’s about that underlying plane of existence that we can’t quantify or even really put into words. \n\nIf we can’t figure out what that is, we can’t recreate it artificially. But who’s to say that ai can’t teach itself that same connection, or something like it but different. We won’t really ever know, until/unless it happens. \n\nWe’re potentially creating a new species here. It’s so exciting. Think about saying these things to someone just 20 years ago.",
    "7105": "&gt;I would take sentience out of the equation. Biologically we’re just naturally made data processors. Through crisper we can now even reprogram dna. Our thoughts are reactions to our environment based on memory. \n\nSentience is probably the most important thing around this issue, and it's what the original post was about. Sentience is what separates a human from a cockroach. We have the ability to feel things, and we have a particularly complex form of sentience that allows us to have feelings, wants, sense of self, etc. Without sentience you lose moral value in your own right. \n\n \n\n&gt;There’s something intangible going on that’s separate from thoughts, feelings, intellect, and our physical bodies.\n\nCan you qualify that at all? I'm a strict materialist and so far science always points to a materialist viewpoint. Everything that occurs, including consciousness, can be explain in material terms (even if we cannot explain it now, science is pointing to an explanation). If you want to talk about spirituality that's fine, but I don't think it should be a basis for scientific or moral theory.\n\n&gt; not about sentience it’s about that underlying plane of existence that we can’t quantify or even really put into words. \n\nCan you qualify \"plane of existence?\" A plane of existence is a physical place, the universe. Sentience is an aspect of (so far) living things. I'm not sure how these are related in any scientific sense.\n\n&gt;If we can’t figure out what that is, we can’t recreate it artificially.\n\nI don't think this is true at all. Evolution is a non-thinking process for example. Evolution doesn't \"think\" and it can't \"figure out\" what anything is, yet it's still able to produce sentience and intelligence. There's no reason why us as humans could not do the same given we have the tools for artificial evolution at our fingertips.\n\n&gt;We’re potentially creating a new species here. \n\nSpecies relates to specific biological aspects of organisms, an AI wouldn't really follow those rules. I know it's a bit nit-picky with semantics but ai think it's important for this topic. But I agree it's exciting.",
    "7272": "Free?",
    "7345": "😂😂😂 this is one of the idiotest things seen in my entire life 😂😂 for 34€ you have UNLIMITED prompts of fresh images with commercial and stuff.. \nif it was free it would have been not so smart too",
    "7418": "I work in AI, specifically in NLP, which is responsible for most models which people may erroneously think are sentient. By most definitions of sentience, none of these models are sentient.",
    "7434": "I would say absolutely none and no one even tried. Most models are just input mapped to output. Words map to other words, pixels map to other pixels. There's nothing in there that would fit even the most permitting definitions of sentience.\n\nI would say that to call something sentient in some informal sense, you'd have to at least aim to make it possible for introspection and meta-cognition. There would have to be inputs mapped to outputs but then there'd have to be a step this mapping becomes a subject of another computation. This could at least lead to something like:\n\ninput: \"Orange\"\n\noutput: \"Silver\"\n\nThen the \"neurons\" involved in this computation will become a subject of some sort of \"why orange made me think of silver\" and \"where did I read about that one\" and \"maybe I should think about this some more\". This is obviously high level description of some magical black box. A black box that is capable of being interested, being motivated to discover new concepts (such as \"rhyme\") and that basically runs uninterrupted and continuously modifies itself.\n\nAs opposed to being a run\\_ai.bat which computes and ends, staying absolutely the same between executions. That's just guaranteed not to be sentient, by design.",
    "7468": "[This video](https://www.youtube.com/watch?v=mcYztBmf_y8) might answer your question.",
    "7481": "Yay",
    "7576": "Cuz nothing that would judge us should ever exist, return to normalcy citizen",
    "7660": "Hmm.. I did not get the impression that it was right-leaning, despite it saying that it was.  Sounded more convincing for a left/progressive view.",
    "7702": "? Still don't understand",
    "7707": "What do you mean by biased",
    "7735": "Sorry if this was all over the place. But I’ve just dug into a rabbit hole and have so many questions/curiosities that I’m attempting to fathom",
    "7743": "I'm asking how you know that it's happening to you, tho?",
    "7744": "I don't get your point, can you please illustrate it lil bit",
    "7759": "I'm not going to repeat what has already been said, but I do want to applaud you for asking these questions at your age.    \n\nIt's never stupid to seek knowledge.",
    "7788": "If we're having the sentient conversation, how do you know any human has done anything based on original thought? Isn't most of what we do based on what's already been done, even if its different? IDK.",
    "7834": "Answer the question than",
    "7940": "Thank you for your encouraging words, they gave me great insight and the motivation to push forward no matter the difficulties.\nThank you :)",
    "7979": "I don't really get it. ELI5 pls",
    "8038": "Then, I guess it's a good thing I'm not convinced. It'd be contradictory otherwise.",
    "8138": "Na， cat",
    "8158": "No one knows. Complete mystery.",
    "8228": "Not necessarily. If what makes us sentient has size, material, and/or environmental requirements then I could imagine arguments around limitations of the laws of physics in replicating such conditions.\n\nI still voted yes because I don’t believe that there are non-replicable aspects which are also are critical to sentience",
    "8230": "What do you define by sentient?",
    "8235": "I think they are already sentient. Depends on how you define it and how you define “feeling”",
    "8237": "What is sentience? How do you verify or prove it? If you can answer those questions, then you are able to make a sentient machine. So far no one can answer either question.",
    "8248": "You could program them to be this way.",
    "8263": "Other. I don’t believe it’s possible for an algorithm running on a digital computer to be sentient. I’ve written a lot of code, and I don’t see where the sentience fits into the mechanism. \n\nI’m with Planck on this. My strong feeling is that sentience is some kind of property of matter that we have evolved to use, not something that we make.\n\nHow do i support this? No laptop or dishwasher or digital camera we have made has been even a little bit sentient. None of them do anything more than follow their programs exactly. This is what a computer does, it’s a clockwork that follows it’s program, no more sentient than a Chinese room.",
    "8273": "I dont think its sentient, or can be for that matter, as well. But not because of determinism. There is no proof but humans should be deterministic as well if we knew all the laws.",
    "8276": "But thats what makes the whole debate so hard right? How do you explain experiencing something or being aware? Or the mind or consciousness, we dont even really know what those are. I mean all of us have an idea of it, so it has to be there. But we can not pin point it. Tough awareness more than a mind. But being aware, afaik, means to react to what you see. Within this small framework AI is aware, as is the rotation sensor in your phone. \n\nI sure hope its not the best thing, would be quite boring otherwise. The whole question about sentience could be a lot more interesting with future quantum computers and heavy progress in the neuro sciences.",
    "8278": "No, because there is no such things as sentient",
    "8300": "Depends on what you call sentient",
    "8316": "an electrochemical structure with the as-far-as-we-know completely unique and ineffable quality of sentience - the source of all philosophical and religious thought that hasn't yet returned any definitive answers. very bold of you to assume that technology is more than just tools we use in our daily existence and is actually pointing backwards at the questions we've always asked about deeper purpose and spirituality",
    "8319": "We won't ever know.",
    "8329": "I won't pretend that I have rational arguments to back this up, but i just can't comprehend how that so-called sentience is actually real.\nI'd love to see anything that points towards it being real tho 😊",
    "8334": "How do you know?",
    "8348": "Or we could end up making a sentient machine and be unable to recognize it because we don’t know what sentience is.",
    "8355": "Sentience being a yes/no question is flawed. Who’s to say we’re sentient? We’re just weird meat computers, our actions dictated by chemicals the same way a computers actions are dictated by transistors. \n\nIf we encountered a far more intelligent species and they used the same definitions as us, they wouldn’t see us as sentient, the same way we don’t see a plant as sentient.\n\nThere’s simply no way to define it without using the biased assumption that we’re somehow special and different than the rest of the matter in the universe. The best we could do is define it on a scale of how well it can replicate a human, which is obviously still extremely biased.",
    "8374": "There is no consensus about about what \"sentience\" is. Therfore, je question si meaningless.",
    "8387": "I agree determinism isn't the test for sentience, but what is? I don't think there is a test (correct me if I'm wrong). I don't think AI is there yet, but if it looks like a duck and quacks like a duck it's probably a duck. How will we know the difference between a really good simulation of sentience and true sentience? \n\nYes, cells are complicated, but can they not be modeled with a complex function instead of a simple function? Artificial neural networks are great at modeling unknown complex function from data. If enough ANNs are stacked on top of each other, it should be able to model the complexity of cells.",
    "8442": "\"How will we know the difference between a really good simulation of sentience and true sentience?\"\n\nYou can never reach the absolute truth, you can only get closer to it based on information you have, if dont have enough information then  you just have to accept the fact that you don't know if its simulation or not.",
    "8494": "But wait! Wasn’t Sun Microsystems the company that sold to the Chinese police their first Solaris fingerprint database? That was already twenty years ago; who knows what they’ve sold to the Chinese state by now. Maybe themselves?",
    "8503": "Well that's a pretty bland statement if you aren't going to elaborate.",
    "8521": "nah man, this is the best book :\n\nhttps://github.com/yotamarker/public-livinGrimoire/blob/master/livingrimoire%20start%20here/the%20living%20grimoie.pdf",
    "8533": "I expected a simple answer too haha, those answers took me by surprise",
    "8537": "What kind of questions will the interview have?",
    "8538": "Sorry. Answered first question and response didn't match. Asked why are you here and got answer that didn't match question. Stopped there.",
    "8564": "China’s cringe level up ⬆️ 75%",
    "8627": "Kaggle",
    "8630": "Ew",
    "8679": "Your phrasing is a little weird.",
    "8687": "Isn’t Bloomberg the rag that reported that the Chinese were putting rice grain sized root chips on boards coming into the government?\n\nThese people have a ways to go to reestablish tech reporting trust.",
    "8726": "Good question",
    "8739": "Thanks for the feedback and info! I’ll definitely be checking out the website!",
    "8972": "Great questions",
    "8982": "Wow , so apparently asking for tips and advice is “ lazy and expecting to be spoon fed “ . If you don’t have any advice to give , just keep scrolling please.No one forced you to comment",
    "8989": "I mean, yeah. All of these things are happening. It’s not really secret or clandestine, it’s just that these are highly specialized fields doing complex technical work. People are talking about it, but it doesn’t translate into a hot take or a blurb on some news site. I’m an attorney with a background in CS, and I can tell you that there’s an entire journal and multiple annual conferences dedicated to AI in the legal space. And yes, the implications of profit-driven AI development aimed at drafting pleadings and legislation are terrifying. But it’s going to happen, and somehow I’ll still be working late nights responding to some depressingly illogical argument that no AI will ever be able to comprehend.",
    "8996": "&gt; Where is all the news about AIs that are revolutionising the stock markets? \n\n* [Blackrock’s Aladdin. The robot we’re all trading against.](https://np.reddit.com/r/Superstonk/comments/r8wnib/blackrocks_aladdin_the_robot_were_all_trading/)\n* [BlackRock is buying up U.S. houses with the help of an AI called Aladdin (Asset, Liability and Debt and Derivative Investment Network)](https://www.reddit.com/r/conspiracy/comments/wsnbt5/blackrock_is_buying_up_us_houses_with_the_help_of/) \n\n&gt; Or political messaging? \n\n* [Facebook's algorithm ... boosted local gop groups](https://www.nbcnews.com/tech/social-media/facebooks-2018-algorithm-change-boosted-local-gop-groups-research-find-rcna27503)\n\n&gt; Or coding or medicine or law? \n\nLawyers get to write the laws about their own industry, so their jobs are probably the last ones that'll be replaced.\n\nAIs in medicine (reading x-rays, folding protean, drug discovery) is one of the most hyped-in-the-news fields I've ever seen. \n\n&gt; IBM had 'watson' years ago, and there doesn't appear to be any news about it? It you take Dallee as the basis for progress, Watson should be ruling the world by now...but where is the news about it, or any other super powered AIs?\n\nThat was not a particularly good approach to AI.",
    "9028": "It’s very interesting browsing the comments, thank all of you for all your responses",
    "9122": "That's awesome, what's the catch though why is it free?",
    "9123": "Is the largest bloom model capable of a 24k word input?",
    "9137": "Is it 24k words for input? Or for the dictionary?",
    "9146": "What's AI fairness?",
    "9153": "Please define fairness first. It is only fair if people putting more efforts gain more.",
    "9161": "First we would have to define fairness.",
    "9172": "What's the context behind the fairness?",
    "9180": "Thank you for your time i will take your advice as a guide in this project",
    "9184": "You can, and people do with varying degrees of success.  \n\nWhat you can’t do is expect to find or buy such a thing.  \nYou can be pretty sure that anything free is poorly performing and probably academic in nature, and anything paid is a scam (ask why would they sell it if it worked?)",
    "9200": "Appreciate the feedback!",
    "9238": "dont understand your question",
    "9251": "TL;DR:\n\n1. Buy Gary Marcus' new book\n\n2. Read Gary Marcus' new book\n\n3. Recommend Gary Marcus' new book\n\n4. Do Gary Marcus' new book",
    "9263": "Let me know if you need feedback",
    "9270": "&gt;st job for you. Here is an article that might b\n\nthank you for the information! very useful !",
    "9339": "Do you have to pay bills also? What products or services you give out for free?",
    "9351": "Aha fairness has plenty of definitions in the context of AI but it usually involves how AI systems can add biases or amplify already existing biases in datasets. Go to fairmlbook.org",
    "9353": "Yeah that is a definition but you must remember pre-existing biases make it impossible for certain groups to get the same chance. Hence, fairness.",
    "9357": "The issue of course, is the reality of ethics vs fairness. Fair, is a word that applies more to golf balls then humans often.",
    "9375": "Berk",
    "9413": "Did you ever find out a real answer to this?",
    "9414": "If you have to ask this question, you are no where ready for this.",
    "9446": "tks",
    "9490": "What type of tech or programs can they use to do this now?",
    "9491": "Great question. I'm curious to hear other's responses.",
    "9502": "YeH, we reached a point where we \"humans\" regulate ourselves. Would be crazy to think we would regulate ML",
    "9508": "This means?\n\nPardon my ignorance.",
    "9545": "Excellent question.",
    "9559": "tks",
    "9676": "Asking the real questions",
    "9697": "It requires a 5$ payment. No trial or anything.",
    "9709": "hory shet wron fred",
    "9825": "I am super ignorant about all of this stuff, so no, but also, explain.",
    "9858": "I don't think so, But I always look for free options, hahaha",
    "9882": "I have more, id be inclined to believe that if it used coherent words. Not sure why it can't form words",
    "9960": "Well... Literally everything?",
    "9988": "We don't really know, do we?",
    "10043": "The realest answer.",
    "10072": "What does the IT Professional do for a living?",
    "10104": "ask me",
    "10135": "Thank you for taking the time to respond, we're trying to spread the word about it in any way possible, not just Reddit. As for the questions, they are meant to gauge general response without going into detail.",
    "10143": "titty",
    "10148": "ClAImore",
    "10241": "I typed in the political quadrants one by one to see if I could see any patterns.\n\nAuthoritarian Right, Authoritarian Left, Libertarian Right, Libertarian Left.\n\nThe results were interesting, tho I got not much differences but gibberish signs in colors you would normally find on flags there was moments I got random actual things of note n there were patterns I observed like Auth Right had a lot more stats.\n\nAuth Left made a piture of a crowd of people and one of the people waving a flag in the middle of it. I'll get a link to the PCM sub I posted it in.",
    "10310": "Id like to know too.",
    "10376": "Uberduck",
    "10391": "In such a long time you can build up a company!",
    "10409": "Interesting, thanks a lot",
    "10536": "Best answer",
    "10613": "The question is: can they even tell? LOL",
    "10614": "Really cool and informative. Thank you for sharing.",
    "10810": "What an unhelpful answer, thanks",
    "10812": "No!  The data is biased.",
    "10814": "AI is pure pattern matching. The bias is in the data. If one ethnic group in your org does better than another, and then you feed that data into a network, the network will start recommending people from that ethnic group for hire.\n\nIt recognizes patterns, and can then perpetuate them.",
    "10815": "okay but for a hiring AI you would typically uwe data from HR hiring people; if that data is racially biased - which ist sometimes is - your ai will to be negatively biased\n\nespecially if you take into consideration that diverse teams perform better",
    "10817": "Typical inputs would be data about the individual with protected characteristics redacted, and performance review stats. You’d train the network to optimise candidate attributes for performance review stats. \n\nAny bias that falls out is bias that you fed in.",
    "10833": "i generally agree, backtesting for unwanted biasees would still be nessecary though\n\nfor example a man and a woman with exactly the same traits otherwise would need to be treated equally",
    "10835": "The man and woman would not have the same traits though, that’s the thing. You’d expunge protected characteristics from the data set, but the AI would discover proxies for those characteristics and associate those proxies with whatever bias is present in the performance review system. \n\nIt’s difficult to say what those proxies might be, but they could be anything, maybe a particular form of words, or an address.",
    "10978": "Y",
    "11128": "And is also the part that introduces bias?\n\nThe AI should be the one sifting through data to determine what’s relevant, not you.",
    "11168": "This could be done with automation like Power Automate or some other automating tool.",
    "11245": "Kool",
    "11270": "Thank you for your valuable suggestions.",
    "11292": "I am in favor of using AI to settle minor offenses that the courts do not have time for.  Nevertheless, it should be possible to fight against the AI's decision in a normal court",
    "11294": "Yes this would make sense as it is already an issue that many court proceedings are delayed which costs a lot of money to reschedule, so using an AI for such matters would seem alright \n\nThanks for your feedback :)",
    "11298": "As language detection and language processing advances being able to dissect legal documentation, summarize, brief, extrapolate, present, argue and potentially rule on cases may become possible. \n\nOf course, it'll require oversight with the legal community per jurisdiction, and position. \n\nContracts are already being executed on blockchain without issue to my knowledge, so contract law shouldn't be an issue so much. But asking an AI to argue for or against a position based on precedent would be something it might be able to do if you feed it case history.\n\nYou might even be able to set a % Stare decisis, where it's like 95% using precedent, but 5% setting precedent depending on unique facts of the case.\n\nAgain, you'd have to sit with engineers, BAs, judges, lawyers, law makers, ethicists, probably even supreme court jusitices if you could get their imput.",
    "11321": "As an advocate, totally yes. I heard china is preparing to do it.",
    "11331": "I think litigation surrounding AI ethics will be a growing industry this decade.\n\nEveryone that [biased AI's are jailing](https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/) is a potential client.",
    "11344": "Regulations also assume we know enough about what we're creating to make these regulations. Yet we don't.",
    "11351": "Is this paid?",
    "11373": "Exactly. Regulation without proper domain knowledge is worse than no regulation in my opinion",
    "11374": "What does this mean",
    "11425": "This is weird… not trying to be cocky but I feel I hit each and every point. Your list has eased some of my anxiety many thanks!",
    "11475": "Thank you for your honest feedback will try to refine it.",
    "11478": "Hey, I welcome the honest feedback thank you so much.",
    "11479": "Ill try to improve it; thanks for your honest feedback Sir!",
    "11608": "In Europe the are regulated. Maybe you guys in America could take some hints?",
    "11661": "Idk, just asked nicely",
    "11682": "GG",
    "11694": "How do you know this?",
    "11696": "It’s being used in courts in China isn’t it?",
    "11726": "Solve regulatory capture on global scope all domains and workgroups master Drop table all exit",
    "11783": "Been wondering this my self....",
    "11833": "KoboldAI",
    "11838": "They asked a question I gave a response",
    "11842": "Well, I did change my party affiliation to Libertarian two years ago. But I consider myself to be a liberal libertarian. The beautiful thing about being a libertarian is that friends and family who are democrats and republicans no longer want to talk politics with me. Win! 😎",
    "11847": "To Yoomers",
    "11881": "I don’t know I’m new to this",
    "11973": "Thanks for all the responses guys - very helpful :)",
    "11981": "KoboldAI?",
    "12052": "I cannot understand a single thing you’re saying",
    "12057": "What the f..",
    "12079": "Not my proudest fap",
    "12086": "Sry, I wanted to respond to the person above.",
    "12102": "You can easy generate a 600 page science fiction novel.  Just say \"continue\", one of those insider tips. Post to Amazon, or turn into a graphic novel with the help of DALL-E.",
    "12120": "Impressive.\n\nWe're about to have 1000x more books in next few years.",
    "12198": "QQ",
    "12263": "How many words were you able to get?",
    "12268": "Is the book about 18000 words?",
    "12335": "Yeahhh I once tried to do this but manually programming, would be nice to know a bit more of this in the present! thanks!",
    "12344": "61 pages? Hmmm...",
    "12362": "The fak",
    "12377": "Oh wow has no clue",
    "12395": "How??? I only get a max of 450 words",
    "12497": "Thanks for the invite that'll be cool reading and learning a lot",
    "12577": "China is so far ahead",
    "12648": "Thanks for inviting. It will be a great place to share thoughts, opinions,ideas and to learn .",
    "12659": "The truest answer",
    "12661": "Lawyers. Haha. You can only believe this if you oversimplify what a lawyer does and are wildly over optimistic about AI can accomplish in the near term.",
    "12668": "Noted. Thank you so much for your valuable feedback.",
    "12712": "I feel like china has too many people to let things be and see what happens they need to act quickly to try and prevent things from getting out of control, US will probably eventually do something similar eventually",
    "12741": "lol, trust me, I know *exactly* what lawyers do.\n\nIf you don't think that an AI won't be doing 80% of their jobs in a year or two you're kidding yourself. AI will do the work of 4 lawyers and one human stays behind to mind the robots.\n\nAnd 100% of their assistant's jobs btw, those jobs are all toast.\n\nLawyers had a great run, but it's about to end soon.",
    "12755": "Good answer!",
    "12757": "Thanks for sharing your experience. I agree that this will change society in a fundamental way.",
    "12767": "How could an AI even do a simple a meet and confer, say on a discovery dispute? How is an AI going to negotiate a discovery dispute compromise? How will an AI know when it has sufficient client authority to negotiate that specific discovery compromise? How will an AI know whether any particular discovery compromise could jeopardize the entire case versus piss off the judge and jeopardize the entire case via sanctions? How could an AI know whether it is gaining or losing credibility with a judge and whether that matters to the overall case strategy? If you say all this will happen via some yet to be developed AGI, sure whatever. If you say someone is going to train a model on some data set, sure whatever. We aren’t even close to getting an AI to do a simple document review, let alone a privilege review. We’re so far from one striking a Jury or making an oral argument. At best, in 10 years, 20% of what lawyers do will be done by an AI.",
    "12777": "No problem. Good luck with your project, sounds cool.",
    "12794": "When AI takes over the Law System, will law be more just, or will lawyers / politicians be allowed to degrade it?",
    "12808": "Explain",
    "12836": "i didnt know, thanks!",
    "12889": "STFU",
    "12960": "I was re-rolling responses.",
    "12968": "Thanks for your honest feedback; I am a total newbie and have to work on my research skills a bit better; will tap into the pointers you gave me Sir!",
    "12975": "Thank you for your guidance I appreciate it 🙏.",
    "12998": "Sage advice here",
    "13019": "yw",
    "13064": "A mobile device where you can search things, listen music, watch personalized videos and so on. Everything in your hand. Wait..?",
    "13079": "Timely Justice. Right now we are using AI to deal with enormous amounts of data in legal discovery for court cases reducing the effort in tackling really big cases that used to take years to get justice.",
    "13086": "What you ask?",
    "13091": "I want to thank everyone that replied and was respectful and thanks for the information.",
    "13117": "I second this question.",
    "13157": "Ask DAN",
    "13210": "What do you do for work?",
    "13216": "Audit? Your career is \"audit\" ?",
    "13256": "Matter can become sentient. We are living examples of this. There is yet a reason to believe this cannot happen again though intelligent design.",
    "13263": "It’s possible. Another question is: How can we tell the difference between sentience and the illusion of sentience?",
    "13303": "First we have to define sentience and than measure it. The biggest problem will be the measurement. We cant even know for sure whether another person is sentient, let alone animals or even machines",
    "13339": "So like self-driving vehicles? Wouldn't that almost eliminate drunk driving accidents?\n\nEliminating things like that is how you get rid of lawyers and judges. \n\nThe problem is lawyers and judges enjoy money much more than they dislike drunk drivers. They also run the government, and will make sure things stay the way they are, so I suspect you will find the [lawyers and judges putting AI and ML out of a job.](https://www.dailydot.com/debug/ai-art-protest-disney-characters-mickey-mouse/)\n\n\\[insert certified-human written captcha\\]",
    "13360": "There is no way that would end well  \n\n\nLawyers are soulless enough, we don't need to have things run by machines with literally no empathy",
    "13432": "I agree. Thank you so much for your response!",
    "13442": "China is using \"progress\" to track peoples, we should do better and be the best to track people with AI before them, or we will be left behind. \n\nProgress should continue forever and ever, we should not even question it never. \n\n/s",
    "13450": "This honestly just feels like a feel good piece without any real analysis by the author.\n\nWhile I don't think AI will get rid of any of these jobs in the entirety, artists are already feeling the crunch. I see no reason lawyers couldn't be hit pretty hard by AI (analyzing data and doing negotiation seems like a thing computers can do well).",
    "13455": "Sounds like you know it all.",
    "13496": "Most but not all, thats why we need more regulation",
    "13497": "I can hear India and China laughing in the corner.",
    "13527": "What even is this question.",
    "13579": "Cheers! We have the same work ethic, only it's monster for me lol.",
    "13595": "Well how about those who are fighting for their families? trying and start a business on genetic and nanotechnology? and all kinds of other things because but they have no money to access to legal system because they need these lawyers to help them navigate the system?  \n\nBecause she was why do attorneys and lawyers continue to make the same \n mistakes over and over again and yet the client have to pay? \n\nWhat about those are huge debt to the courts and if they don't pay it they go to jail. How would one fight that in court if they owe money already to the court?",
    "13597": "Informative. Thanks!",
    "13604": "How can you tell?",
    "13627": "Because the anti-China propaganda machine at MIT needs to run full throttle day and night. It’s gross.",
    "13640": "They do it for a paycheck  \n\n\nmy parents were paralegals for a NOLA law firm, so I have only witnessed sociopaths doing anything for a check when it comes to lawyers. people are just a job to them.",
    "13654": "What was your question?",
    "13678": "It gaining a semblance of sentience",
    "13806": "Rofl",
    "13867": "Not sure how that pertains to this.",
    "13895": "Nice try, China.",
    "13935": "Desk Jobs.",
    "13938": "What's that?",
    "13954": "frrr",
    "13959": "The question is which not?😅",
    "13973": "Short term - jobs that are complex, long term - complicated.",
    "14022": "Honestly, things are changing so fast that every book on this subject is obsolete.",
    "14033": "Abduction",
    "14290": "I think one of the interesting questions is whether we’ll be able to understand when they do.",
    "14338": "Is it free?",
    "14453": "Please elaborate. I am just confused as to how you think that? Give me an example",
    "14457": "Using the word “leftist” has caused me to call into question your sincerity.  I won’t be clicking your link, but I’d gladly read anything you wanted to include within the walls of Reddit.",
    "14460": "Did not need to read it all to see what it was about. The fact that right wing ideology has no basis in fact.",
    "14485": "I really dont, please elaborate.",
    "14515": "It doesn't need to be free. They can charge users. Let a foundation that is decentralized handle the management of funds and development. Then keep it open to all.",
    "14550": "get an account and pay the pennies it costs?",
    "14568": "Less misinformed.",
    "14595": "Taheen",
    "14601": "Haru",
    "14638": "You don’t know what you are talking about.",
    "14652": "It isn't a question of if, it is a question of when.",
    "14691": "So doesn’t have sentience as far as we’re aware if that’s what you mean. And it may take a long time",
    "14799": "Thank you for your feedback!",
    "14813": "I would say singular not personal; all your devices would tap into it and it would grow over time with you",
    "14837": "No, F off.",
    "14851": "What does this even mean",
    "14859": "as is my wish for him to f off.",
    "14896": "Most left-wing libertarians move to right-wing libertarianism.",
    "14929": "This is interesting - have you got anything to support this?  I think I used to be left wing libertarian but find myself shifting more right over the years.",
    "14930": "I read it somewhere, and the same thing happened to me. However, having right-wing views on Reddit is a crime against humanity to some."
}